{"cells":[{"cell_type":"code","execution_count":1,"id":"6f08001b-c05e-4cf1-ad28-6657571b08a0","metadata":{"id":"6f08001b-c05e-4cf1-ad28-6657571b08a0"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"markdown","id":"364df6ec-5a75-43a5-a180-532cb14cb305","metadata":{"id":"364df6ec-5a75-43a5-a180-532cb14cb305"},"source":["# Operaciones con tensores"]},{"cell_type":"code","execution_count":2,"id":"fb2eea9d-d11e-441e-9d3f-c6cc61537195","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1699,"status":"ok","timestamp":1705318363038,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"fb2eea9d-d11e-441e-9d3f-c6cc61537195","outputId":"32b286f7-aa63-45db-d415-9af789875c30"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["a = tf.convert_to_tensor([1, 2, 3])\n","a"]},{"cell_type":"code","execution_count":3,"id":"c0f30984-2237-4969-94dc-1d011261ff7c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1705318374266,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"c0f30984-2237-4969-94dc-1d011261ff7c","outputId":"d5e28512-ce7b-4394-a7d3-a359c022372a"},"outputs":[{"data":{"text/plain":["TensorShape([3])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["a.shape"]},{"cell_type":"code","execution_count":4,"id":"575cf0f0-51dc-40ee-a4f1-c104bba4d80b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1705318378487,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"575cf0f0-51dc-40ee-a4f1-c104bba4d80b","outputId":"5646f442-837f-44a1-d7f5-da83b572bf6d"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 6], dtype=int32)>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["2 * a"]},{"cell_type":"code","execution_count":5,"id":"4b0e936e-aa2e-4caf-86d9-187d883d4afb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":248,"status":"ok","timestamp":1705318389296,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"4b0e936e-aa2e-4caf-86d9-187d883d4afb","outputId":"78ee9d72-9a2f-46e2-beb0-b52d1f0e150a"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3,), dtype=int32, numpy=array([ 6,  8, 10], dtype=int32)>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["b= tf.convert_to_tensor([5, 6, 7])\n","a + b"]},{"cell_type":"markdown","id":"e9a353cc-754e-42ec-981a-aea893242dbe","metadata":{"id":"e9a353cc-754e-42ec-981a-aea893242dbe"},"source":["# Layers de keras"]},{"cell_type":"markdown","id":"26375e82-6b03-468a-bbee-a0e1259235b3","metadata":{"id":"26375e82-6b03-468a-bbee-a0e1259235b3"},"source":["## Dense"]},{"cell_type":"code","execution_count":6,"id":"b9865824-4107-4f4a-bdbb-2371acbffeac","metadata":{"id":"b9865824-4107-4f4a-bdbb-2371acbffeac"},"outputs":[],"source":["layer_fully_connected = tf.keras.layers.Dense(units=20, input_shape=(3,),  activation=\"tanh\", name=\"fully_connected_network\")"]},{"cell_type":"code","execution_count":8,"id":"d0481214-1607-417e-9f67-2940b5738d7e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":242,"status":"ok","timestamp":1705318478057,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"d0481214-1607-417e-9f67-2940b5738d7e","outputId":"f75fbf3e-54f7-489e-df35-f3965d5af1b4"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 20), dtype=float32, numpy=\n","array([[ 0.98796105,  0.68167347, -0.8317487 ,  0.6822494 , -0.94891936,\n","         0.60169   , -0.87907505,  0.02645102, -0.8311211 , -0.9437486 ,\n","         0.85994685,  0.6153214 , -0.32393873, -0.7024941 , -0.6812314 ,\n","         0.95068973, -0.00235253, -0.94090223,  0.8106788 , -0.87052256],\n","       [ 0.9999997 ,  0.99511987, -0.9193917 ,  0.96714664, -0.99927205,\n","         0.99629724, -0.9976895 , -0.50894654, -0.9532794 , -0.9996165 ,\n","         0.9989381 ,  0.96232474,  0.19237956, -0.9941049 , -0.99594206,\n","         0.999439  ,  0.31012866, -0.9996526 ,  0.9464856 , -0.9986753 ]],\n","      dtype=float32)>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["input_data = tf.convert_to_tensor([[1, 2, 3], [5, 6, 7]])\n","\n","layer_fully_connected(input_data)"]},{"cell_type":"code","execution_count":10,"id":"60436eac-94c3-4afc-933e-624ffd2f65bc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1705318595749,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"60436eac-94c3-4afc-933e-624ffd2f65bc","outputId":"8fc2b3c7-bc36-4818-8db4-b48b3ca37441"},"outputs":[{"data":{"text/plain":["[<tf.Variable 'fully_connected_network/kernel:0' shape=(3, 20) dtype=float32, numpy=\n"," array([[ 0.48736626,  0.16643673,  0.4884714 , -0.04306218,  0.31304026,\n","          0.4904948 ,  0.0348767 , -0.03808188,  0.4693576 ,  0.18796355,\n","          0.23890507,  0.1898207 ,  0.24695343, -0.26914525, -0.3593489 ,\n","         -0.31046838,  0.35537618,  0.08025074, -0.2921353 , -0.28827327],\n","        [ 0.4090948 ,  0.46570247, -0.07663238,  0.1624394 , -0.4088944 ,\n","          0.16011816, -0.20517328, -0.39111662, -0.2530573 , -0.4858535 ,\n","          0.08680445, -0.15283197,  0.24027085, -0.11928651, -0.15066245,\n","          0.46990436, -0.46611965, -0.35208535, -0.04380378,  0.16856205],\n","        [ 0.4159351 , -0.08853608, -0.50966346,  0.18383116, -0.43868804,\n","         -0.03831303, -0.33207083,  0.28225744, -0.38499784, -0.32917604,\n","          0.29354215,  0.27776122, -0.35451218, -0.12149644, -0.05691144,\n","          0.40318775,  0.19150352, -0.3739791 ,  0.5029163 , -0.46136138]],\n","       dtype=float32)>,\n"," <tf.Variable 'fully_connected_network/bias:0' shape=(20,) dtype=float32, numpy=\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0.], dtype=float32)>]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["layer_fully_connected.weights"]},{"cell_type":"markdown","id":"61539a83-080f-4d0e-ae72-f7033637de8f","metadata":{"id":"61539a83-080f-4d0e-ae72-f7033637de8f"},"source":["## Embedding"]},{"cell_type":"code","execution_count":11,"id":"4f34493f-0602-4db2-96f3-f7e42a562f83","metadata":{"id":"4f34493f-0602-4db2-96f3-f7e42a562f83"},"outputs":[],"source":["embedding = tf.keras.layers.Embedding(input_dim=10, output_dim=4, name=\"embedding\")"]},{"cell_type":"code","execution_count":12,"id":"e688cc3e-e188-46db-8d9d-2a048ebc640c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":266,"status":"ok","timestamp":1705319039065,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"e688cc3e-e188-46db-8d9d-2a048ebc640c","outputId":"263c2e8f-46b5-4808-bd79-7b98d123cb13"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n","array([[-0.04214694, -0.03316452,  0.04542165,  0.04758637],\n","       [-0.03672953,  0.00341352, -0.00357755,  0.0393678 ],\n","       [-0.04214694, -0.03316452,  0.04542165,  0.04758637]],\n","      dtype=float32)>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["input_data = tf.convert_to_tensor([1, 3, 1])\n","embedding(input_data)"]},{"cell_type":"markdown","id":"d454f429-bb2f-47d6-aab2-5ba03bb17f89","metadata":{"id":"d454f429-bb2f-47d6-aab2-5ba03bb17f89"},"source":["## Merge layers"]},{"cell_type":"code","execution_count":13,"id":"ce209c25-bbda-4495-ab0d-0e9ed09578c5","metadata":{"id":"ce209c25-bbda-4495-ab0d-0e9ed09578c5"},"outputs":[],"source":["a = tf.convert_to_tensor([[1, 2, 3]])\n","b = tf.convert_to_tensor([[5, 6, 7]])"]},{"cell_type":"code","execution_count":14,"id":"5581398c-a0cd-418c-b7cc-693e1321c1c0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":270,"status":"ok","timestamp":1705319061255,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"5581398c-a0cd-418c-b7cc-693e1321c1c0","outputId":"4f48cd81-6ccc-462c-c139-fcab7254d778"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 6), dtype=int32, numpy=array([[1, 2, 3, 5, 6, 7]], dtype=int32)>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["tf.keras.layers.Concatenate(name=\"concat\")([a, b])"]},{"cell_type":"code","execution_count":15,"id":"9ee5d96b-a126-4402-adb6-b1324fe81573","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1705319067031,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"9ee5d96b-a126-4402-adb6-b1324fe81573","outputId":"e02fb80f-5042-48db-b2ff-16efec01fdab"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[ 6,  8, 10]], dtype=int32)>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tf.keras.layers.Add(name=\"add\")([a, b])"]},{"cell_type":"code","execution_count":16,"id":"52217fee-e15b-42cb-b13e-6c20884077d2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1705319083063,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"52217fee-e15b-42cb-b13e-6c20884077d2","outputId":"c4afdbd1-c4ee-4435-b741-fa469a927924"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[-4, -4, -4]], dtype=int32)>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["tf.keras.layers.Subtract(name=\"subtract\")([a, b])"]},{"cell_type":"code","execution_count":17,"id":"1c03dd4b-df6a-479a-a406-181e2885ffc0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1705319086229,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"1c03dd4b-df6a-479a-a406-181e2885ffc0","outputId":"637eba72-3676-4f5c-b12a-896676c14e84"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 3), dtype=int32, numpy=array([[5, 6, 7]], dtype=int32)>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["tf.keras.layers.Maximum(name=\"max\")([a, b])"]},{"cell_type":"markdown","id":"2f6f4aba-c86a-4659-8868-9b9de782bf1d","metadata":{"id":"2f6f4aba-c86a-4659-8868-9b9de782bf1d"},"source":["# Modelo"]},{"cell_type":"markdown","id":"1bfb3e7f-ccaf-4563-aac5-b4167be6e3ed","metadata":{"id":"1bfb3e7f-ccaf-4563-aac5-b4167be6e3ed"},"source":["## Secuencial"]},{"cell_type":"code","execution_count":18,"id":"4d0548fb-3380-42ce-a0f3-d469ca36a315","metadata":{"id":"4d0548fb-3380-42ce-a0f3-d469ca36a315"},"outputs":[],"source":["model = tf.keras.models.Sequential(name=\"sequential_model\")\n","model.add(tf.keras.layers.Dense(10, input_shape=(50, ), activation=\"relu\", name=\"hidden_layer_1\"))\n","model.add(tf.keras.layers.Dense(5, activation=\"relu\", name=\"hidden_layer_2\"))\n","model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"final_layer\"))\n","\n","# ? - The choice of the activation function is pretty specific. ReLU helps us achieve non-linearity, is computationally efficient,\n","# ? - and avoids the vanishing gradient problem. \n","# * - The sigmoid outputs a value between 0 and 1, not 0 and x. Which makes it very suitable for binary classification. \n","# * - It also has very smooth gradients which is a yey for fine-tuning. "]},{"cell_type":"code","execution_count":19,"id":"81c3d720-231e-4963-810d-34f7370dae23","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1705319150493,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"81c3d720-231e-4963-810d-34f7370dae23","outputId":"71611142-1291-473b-a638-c77a64323f10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," hidden_layer_1 (Dense)      (None, 10)                510       \n","                                                                 \n"," hidden_layer_2 (Dense)      (None, 5)                 55        \n","                                                                 \n"," final_layer (Dense)         (None, 1)                 6         \n","                                                                 \n","=================================================================\n","Total params: 571 (2.23 KB)\n","Trainable params: 571 (2.23 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","id":"0a78a434-6d72-4f36-8529-ced5f2043800","metadata":{"id":"0a78a434-6d72-4f36-8529-ced5f2043800"},"source":["## Functional"]},{"cell_type":"markdown","id":"44cc02d3","metadata":{},"source":["- The Sequential model in Keras is a linear stack of layers. It's straightforward and well-suited for most simple neural network architectures, where each layer has exactly one input and output tensor.\n","- Analogy: \n","  Think of a straight water pipe, where water flows from one end to the other through various sections. Performing specific transformations on the flow. \n","\n","- The **Functional** model, is a complex network of pipes. Water can enter through multiple inlets, pass through a network of interconnected pipes, and exit through multiple outlets. "]},{"cell_type":"code","execution_count":23,"id":"b9a34706-123d-46a3-9e47-ff9992bede7f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1705319263543,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"b9a34706-123d-46a3-9e47-ff9992bede7f","outputId":"5b3c2afd-fbae-4be9-fbe5-b52462e9d981"},"outputs":[{"data":{"text/plain":["<KerasTensor: shape=(None, 50) dtype=float32 (created by layer 'input')>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":[" # ? - Define the input layer of the model. The shape=(50, ) parameter indicates that each input data instance is a 1-dim array of 50 features. \n","input_layer = tf.keras.layers.Input(shape=(50, ), name=\"input\")\n","input_layer"]},{"cell_type":"code","execution_count":28,"id":"ed5d6123-f69a-4304-a5f4-292a223144ea","metadata":{"id":"ed5d6123-f69a-4304-a5f4-292a223144ea"},"outputs":[],"source":[" # ? - Heere we add dense layers to the model with 10 neurons. Outputs and inputs are re-fed into it. \n","# ! - As no activation function has been defined in each layer, Keras defaults to a linear activation function f(x) = x.\n","x_1 = tf.keras.layers.Dense(10, name=\"hidden_layer_1\")(input_layer) # * Hidden Layer 1 \n","x_2 = tf.keras.layers.Dense(10, name=\"hidden_layer_2\")(x_1)         # * Hidden Layer 2 \n","x_3 = tf.keras.layers.Dense(10, name=\"final_layer\")(x_2)            # * Output Layer, however no density function has been indicated\n","model = tf.keras.models.Model(input_layer, x_3, name=\"functional_model\")"]},{"cell_type":"code","execution_count":29,"id":"697133d3-dc31-4eca-a3a9-6a87166fa8ae","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1705319360625,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"697133d3-dc31-4eca-a3a9-6a87166fa8ae","outputId":"92625e38-3543-4a4b-8737-92521106f08e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"functional_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input (InputLayer)          [(None, 50)]              0         \n","                                                                 \n"," hidden_layer_1 (Dense)      (None, 10)                510       \n","                                                                 \n"," hidden_layer_2 (Dense)      (None, 10)                110       \n","                                                                 \n"," final_layer (Dense)         (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 730 (2.85 KB)\n","Trainable params: 730 (2.85 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","id":"bb57b130","metadata":{},"source":["We are now going to see a use case for Functional Neural networks: \n","* Useful for multiple inputs and outputs. Different data sources. \n","* Complex architectures for non-linear topology. Shared layers (?), residual connections (?), self-connecting layers (?)\n","* Multi-task learning (?), where the model learns from related tasks simultaneously to improve performance. "]},{"cell_type":"code","execution_count":30,"id":"dd9b7d31-a384-45da-bb2a-3358e1e863e8","metadata":{"id":"dd9b7d31-a384-45da-bb2a-3358e1e863e8"},"outputs":[],"source":["# ? - Having a functional NN, allows us to input different types of data. \n","input_numerical = tf.keras.layers.Input(shape=(1, ), name=\"numerical_input\")\n","input_categorical = tf.keras.layers.Input(shape=(1, ), name=\"categorical_input\")\n","\n","# ? - For the numeric variables, we create a 10-neuron dense layer with the tanh activation function \n","x_numeric = tf.keras.layers.Dense(10, activation=\"tanh\", name=\"encoding_numerical\")(input_numerical)\n","\n","# ? - For the categorical we apply an embedding layer, and a reshape layer, explanations in the following block\n","x_categorical = tf.keras.layers.Embedding(input_dim=5, output_dim=3, name=\"embedding_categorical\")(input_categorical)\n","x_categorical = tf.keras.layers.Reshape(target_shape=(3, ), name=\"flat_vector\")(x_categorical)\n","\n","# ? - We then merge thse layers, and apply 2 final dense layers for a single output. \n","x = tf.keras.layers.Concatenate()([x_numeric, x_categorical])\n","x = tf.keras.layers.Dense(10, activation=\"tanh\")(x)\n","x = tf.keras.layers.Dense(1)(x)\n","\n","model = tf.keras.models.Model([input_numerical, input_categorical], x, name=\"model_with_two_inputs\")"]},{"cell_type":"markdown","id":"06c55503","metadata":{},"source":["![Alt text](image-1.png) \n","\n","### Numeric variables: \n","+ Dense layer, 10 neurons, tanh activation function. \n","  \n","### Categoric variables: \n","+ **Embedding Layer:** A type of layer for handling categorical data, especially with large vocab. It maps each category or word to a high-dim vector of fixed size. This makes the input more informative and suitable for the process. It's also more efficient in terms of parameters than *one-hot encoding.*\n","+ **Reshape Layer:** A reshape layer changes the shape of the input tensor to a specified shape without altering its data. Used when we need to alter the dimenstions to fit the expected input shape of subsequent layers. Useful in CNN's. Imagine we have a tenser of shape (32,32,3) - (width, heigh, color channel) and we want to feed it into a dense layer, which expects a 1D vector. A reshape layer can be used to flatten this tensor into shape (3072, ), making it compatible with the dense layer. "]},{"cell_type":"code","execution_count":34,"id":"d6b30496-25d3-4089-b0d8-56db9f73c7c9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1705319535749,"user":{"displayName":"jpfuentes","userId":"13261195549114262924"},"user_tz":-60},"id":"d6b30496-25d3-4089-b0d8-56db9f73c7c9","outputId":"97d25a33-e786-4853-9407-710cd58bd86e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_with_two_inputs\"\n","______________________________________________________________________________________________________________________________________________________\n"," Layer (type)                                Output Shape                                 Param #        Connected to                                 \n","======================================================================================================================================================\n"," categorical_input (InputLayer)              [(None, 1)]                                  0              []                                           \n","                                                                                                                                                      \n"," numerical_input (InputLayer)                [(None, 1)]                                  0              []                                           \n","                                                                                                                                                      \n"," embedding_categorical (Embedding)           (None, 1, 3)                                 15             ['categorical_input[0][0]']                  \n","                                                                                                                                                      \n"," encoding_numerical (Dense)                  (None, 10)                                   20             ['numerical_input[0][0]']                    \n","                                                                                                                                                      \n"," flat_vector (Reshape)                       (None, 3)                                    0              ['embedding_categorical[0][0]']              \n","                                                                                                                                                      \n"," concatenate (Concatenate)                   (None, 13)                                   0              ['encoding_numerical[0][0]',                 \n","                                                                                                          'flat_vector[0][0]']                        \n","                                                                                                                                                      \n"," dense (Dense)                               (None, 10)                                   140            ['concatenate[0][0]']                        \n","                                                                                                                                                      \n"," dense_1 (Dense)                             (None, 1)                                    11             ['dense[0][0]']                              \n","                                                                                                                                                      \n","======================================================================================================================================================\n","Total params: 186 (744.00 Byte)\n","Trainable params: 186 (744.00 Byte)\n","Non-trainable params: 0 (0.00 Byte)\n","______________________________________________________________________________________________________________________________________________________\n"]}],"source":["model.summary(line_length=150) # * Line length serves to expand the lines when printed. "]},{"cell_type":"markdown","id":"e8403830-e087-4b96-9673-044a32968671","metadata":{"id":"e8403830-e087-4b96-9673-044a32968671"},"source":["# Compile"]},{"cell_type":"code","execution_count":35,"id":"5f62d4be-3c49-48e1-a59e-c68f32c487cb","metadata":{"id":"5f62d4be-3c49-48e1-a59e-c68f32c487cb"},"outputs":[],"source":["model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"area_under_curve\")])"]},{"cell_type":"markdown","id":"00946723-e025-4ae3-bacc-92758015f478","metadata":{"id":"00946723-e025-4ae3-bacc-92758015f478"},"source":["# Fit"]},{"cell_type":"code","execution_count":null,"id":"229928c5-f8df-456b-803c-7f9848f0e767","metadata":{"id":"229928c5-f8df-456b-803c-7f9848f0e767"},"outputs":[],"source":[" # * 1. Probable use case for a sequential API model. \n","model.fit(X_train, y_train)\n","# * 2. Use case for a functional API model with 2 types of input and a single output\n","model.fit((X_train_numerical, X_train_categorical), y_train)\n","# * 3. This is the same as before, however we're now defining the input as a dictionary to specify it more in detail. \n","model.fit({\"numerical_input\": X_train_numerical, \"categorical_input\": X_train_numerical}, y_train)\n","# * 4. Introduction to the concept of a validation split => Proxy to the test dataset. \n","model.fit(X_train, y_train, validation_split=0.2)\n","model.fit(X_train, y_train, validation_data=(X_val, y_val))"]},{"cell_type":"markdown","id":"70080c5f","metadata":{},"source":["### Validation Split in Neural Network Training:\n","+ The validation set is used as a proxy for the test set to tune the hyperparameters of the model (like learning rate, number of layers, neurons per layer, etc.) \n","+ To make decisions about the architecture of the model itself without using the test set. This helps in avoiding information leak from the test set during the model development phase.\n","+ The validation set allows for the ongoing monitoring of the model's generalization ability during training. \n","\n","**Test set is used strictly for the final evaluation of the model - After all tuning, training and validation has been completed.**\n","_It's like trying your food before you serve it, rather than just eating all of it._"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
